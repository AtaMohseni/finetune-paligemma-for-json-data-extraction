{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8cfd6-8f7a-481f-9c54-58187d0af722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bdb40-21bc-4f51-ad50-4401105be5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonlines --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251d848-3af0-489d-ab3a-dcbc25b652a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce9ad4-9dd2-4077-bca9-42538a8913ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U peft --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3bb13-19de-4ad5-8aa5-660709dac578",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eafed2-3d7b-4027-b116-bf8ffebd9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U rouge_score --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdf9fe-2b47-4d26-a30b-3ae30063c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install evaluate==0.4.3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f418c-7965-4ad2-aabb-783b14083426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6235224-80ac-467d-80ff-9f1ce5b194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "import torch\n",
    "model_ID = 'google/paligemma-3b-mix-448'\n",
    "dtype = torch.bfloat16\n",
    "processor = AutoProcessor.from_pretrained(model_ID)\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ab3a6-62c5-43f2-b45f-d213e1bae381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amohseni/receipt_VLM_information_extraction\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e114b-d70e-4d5c-9d52-8fd5cc01ddbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictions = []\n",
    "targets = dataset['test'][0:]['suffix']\n",
    "instructions = dataset['test'][0:]['prefix']\n",
    "for i in range(len(targets)):\n",
    "    prompt = \"<image>\" + instructions[i]\n",
    "    image_file = dataset['test'][i]['image'].convert(\"RGB\")\n",
    "    model_inputs = processor(text=prompt, images=image_file, return_tensors=\"pt\").to(dtype).to(device)\n",
    "    input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**model_inputs, max_new_tokens=512, do_sample=False)\n",
    "        generation = generation[0][input_len:]\n",
    "        decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "        predictions.append(decoded)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f3b8c-3523-4884-b8e9-24e426d8a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "zipped_performance = list(zip(targets, predictions))\n",
    "df = pd.DataFrame(zipped_performance, columns = ['human_baseline', 'model extraction'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0a27a-69f0-49c0-8652-0b3fcb093ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('original_model_extraction_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf25c2-28e9-4637-9e6e-ec136113ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./original_model_extraction_performance.csv')\n",
    "human_base_line_extraction = df['human_baseline']\n",
    "original_model_extraction = df['model extraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0305af-1ac9-4351-9135-d08f2062c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "rouge = evaluate.load('rouge')\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_extraction,\n",
    "    references=human_base_line_extraction[0:len(original_model_extraction)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c8f61-6810-42f0-ac10-5d19b636cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame.from_dict([original_model_results])\n",
    "performance.head()\n",
    "performance.to_csv('./Rouge_original_model_extraction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
