{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221acd4-72b5-4282-9193-f89f82e1c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f666aa0-1351-4a5e-8a9d-f080e80d81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91d6ad-a4d3-4899-8b3b-fbfe1af131e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U peft --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d37da-73cd-41e0-aad5-4e24fcc1c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U transformers  accelerate bitsandbytes --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e4f36-02d5-4b72-a889-04e10900dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install evaluate==0.4.3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2eead-a3fe-464e-9288-9d7cd212983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U rouge_score --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98bab0-bc53-48b9-9d01-6f689e813bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from transformers import PaliGemmaForConditionalGeneration\n",
    "from transformers import PaliGemmaProcessor\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14e583-039a-446a-b88d-e10de345a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b15020-bb6f-43fa-8274-0efd9eb9cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"amohseni/receipt_VLM_information_extraction\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d237804-0fbc-444c-a1f4-6df82b63b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID =\"google/paligemma-3b-mix-448\" \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = PaliGemmaProcessor.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff8f8-ce51-43a6-a4a2-1b264fed033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_LORA = True\n",
    "USE_QLORA = False\n",
    "FREEZE_VISION = False\n",
    "\n",
    "if USE_LORA or USE_QLORA: \n",
    "    lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \n",
    "        \"o_proj\", \n",
    "        \"k_proj\", \n",
    "        \"v_proj\", \n",
    "        \"gate_proj\", \n",
    "        \"up_proj\", \n",
    "        \"down_proj\"\n",
    "    ],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    if USE_QLORA:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_type=torch.bfloat16)\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=\"auto\", \n",
    "        quantization_config=bnb_config if USE_QLORA else None,\n",
    "        torch_dtype=torch.bfloat16)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model = model.to(DEVICE)\n",
    "    model.print_trainable_parameters()\n",
    "else:\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID, device_map=\"auto\").to(DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    if FREEZE_VISION:\n",
    "        for param in model.vision_tower.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in model.multi_modal_projector.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "TORCH_DTYPE = model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c7130-fff6-4ca9-81ee-3764e9b55226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    images = [example['image'].convert(\"RGB\") for example in batch]\n",
    "    prefixes = [\"<image>\" + example['prefix'] for example in batch]\n",
    "    suffixes = [example['suffix'] for example in batch]\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=prefixes,\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        suffix=suffixes,\n",
    "        padding=\"longest\"\n",
    "    ).to(TORCH_DTYPE).to(DEVICE)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50f6c-9bf3-4d32-9de9-ce2522d0ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_steps=1000,\n",
    "    warmup_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-6,\n",
    "    adam_beta2=0.999,\n",
    "    logging_steps=1,\n",
    "    optim=\"paged_adamw_8bit\" if USE_QLORA else \"adamw_hf\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=1,\n",
    "    output_dir=\"paligemma2_json_extraction\",\n",
    "    bf16=True,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    dataloader_pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1859ccd-293f-4dc9-9d7a-f252b416c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    data_collator=collate_fn,\n",
    "    args=args\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbb43d-02c0-4132-8703-a47c1fd87158",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81db5d9-a462-4a46-96e9-6c4c57ee57a9",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e415e1-7d92-46bb-a63f-c1ca6e0a6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "MODEL_ID =\"google/paligemma-3b-mix-448\" \n",
    "peft_model_base = PaliGemmaForConditionalGeneration.from_pretrained(MODEL_ID,device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "processor = PaliGemmaProcessor.from_pretrained(MODEL_ID)\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       './paligemma2_json_extraction/checkpoint-1000/',\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80770a-85ec-4a4e-8745-169653178aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TORCH_DTYPE = peft_model.dtype\n",
    "predictions = []\n",
    "targets = dataset['test'][0:]['suffix']\n",
    "instructions = dataset['test'][0:]['prefix']\n",
    "for i in range(len(targets)):\n",
    "    prompt = \"<image>\" + instructions[i]\n",
    "    image_file = dataset['test'][i]['image'].convert(\"RGB\")\n",
    "    model_inputs = processor(text=prompt, images=image_file, return_tensors=\"pt\").to(TORCH_DTYPE).to(device)\n",
    "    input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generation = peft_model.generate(**model_inputs, max_new_tokens=512, do_sample=False)\n",
    "        generation = generation[0][input_len:]\n",
    "        decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "        predictions.append(decoded)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c62a0-f855-401c-b836-8dd763a9e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "zipped_performance = list(zip(targets, predictions))\n",
    "df = pd.DataFrame(zipped_performance, columns = ['human baseline', 'model extraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec492af-be0b-48f7-b807-2a5bc6157021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trained_model_extraction_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd2205-c988-48c9-908b-4275f3000243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./trained_model_extraction_performance.csv')\n",
    "human_base_line_extraction = df['human baseline']\n",
    "finetuned_model_extraction = df['model extraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c868fc-cf15-410f-be7c-14cc0eb3437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "rouge = evaluate.load('rouge')\n",
    "finetuned_model_results = rouge.compute(\n",
    "    predictions=finetuned_model_extraction,\n",
    "    references=human_base_line_extraction[0:len(original_model_extraction)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('FINE TUNED MODEL:')\n",
    "print(finetuned_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e35b2-237e-43d0-b526-103ad2814eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame.from_dict([finetuned_model_results])\n",
    "performance.head()\n",
    "performance.to_csv('./Rouge_trained_model_extraction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
